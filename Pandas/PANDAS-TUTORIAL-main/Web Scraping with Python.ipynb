{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d7252bc",
   "metadata": {},
   "source": [
    "Subscribe for more [Be.Analyst](https://youtube.com/@Be.Analyst) ðŸ˜€"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43eda106",
   "metadata": {},
   "source": [
    "# Web Scraping with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0f27f7b",
   "metadata": {},
   "source": [
    "## 1. What is Web Scraping?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "046e674d",
   "metadata": {},
   "source": [
    "- Web Scraping is the act of extracting content and data from a website. \n",
    "\n",
    "- Websites are built using Hypertext Markup Language (HTML) codes which web scraping codes or web scrapers can download objects from. \n",
    "\n",
    "- Python is a powerful tool that allows you to use code to web scrape a website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5fb25b4",
   "metadata": {},
   "source": [
    "## 2. Install the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f539d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\durge\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1264 sha256=ea1604c0f848296d840aeca88d612dbaa80468a7bf89bd6f7200a0adbdfbabba\n",
      "  Stored in directory: c:\\users\\durge\\appdata\\local\\pip\\cache\\wheels\\e4\\62\\1d\\d4d1bc4f33350ff84227f89b258edb552d604138e3739f5c83\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in c:\\users\\durge\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\durge\\anaconda3\\lib\\site-packages (from requests) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77aa3087",
   "metadata": {},
   "source": [
    "## 3. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b26d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a6a653b",
   "metadata": {},
   "source": [
    "## 4. Understand the Website"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d2c7b70",
   "metadata": {},
   "source": [
    "The website I'll use in this tutorial is [trendyol](https://www.trendyol.com/). I want to exract laptop information such as price, brand, ratingCount in this website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2634d5c3",
   "metadata": {},
   "source": [
    "## 5. Understand the URL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5f931a9",
   "metadata": {},
   "source": [
    "Understanding how to interact with the URL is important to web scraping. The url I'll use is [here](https://www.trendyol.com/sr?q=notebook&qt=notebook&st=notebook&os=1&pi=1)\n",
    "\n",
    "I'm going to extract information first 10 pages of the website I get the above URL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e32e9829",
   "metadata": {},
   "source": [
    "## 6. Create Empty Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e50e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = []\n",
    "brand = []\n",
    "ratingCount = []\n",
    "info = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af069b2",
   "metadata": {},
   "source": [
    "## 7. Web Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9b869d1",
   "metadata": {},
   "source": [
    "I'll use a for loop, which creates an element pgn that goes through the numbers 1 through 10. The next portion is creating a link, this is broken out into 2 parts of the URL, the last section populate after page = as we identified when researching the URL. Thus, each page will be read using the request statement requests and stored in res. \n",
    "\n",
    "Then the Beautiful Soup package will give us a way to interact with the HTML from the URL and store this in soup. Next, is a series of for loops within our initial for loop: the first aspect of it locates the CSS Selector (note: SelectorGadget used), and inside the loop returns the result as text then appends to the array. The loop runs till it goes through the first 10 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9234379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pgn in range(1,10):  \n",
    "    url = \"https://www.trendyol.com/sr?q=notebook&qt=notebook&st=notebook&os=\" + str(pgn)\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)    \n",
    "    for brand_select in soup.select(\".prdct-desc-cntnr-ttl\"):\n",
    "        brand.append(brand_select)\n",
    "    for ratingCount_select in soup.select(\".ratingCount\"):\n",
    "        ratingCount.append(ratingCount_select)\n",
    "    for info_select in soup.select(\".prdct-desc-cntnr-name\"):\n",
    "        info.append(info_select)   \n",
    "    for price_select in soup.select(\".prc-box-dscntd\"):\n",
    "        price.append(price_select)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71b3aca4",
   "metadata": {},
   "source": [
    "## 8. Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb395ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Rating_Count</th>\n",
       "      <th>Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>(65)</td>\n",
       "      <td>X515ea-bq2293w Intel Core I3-1115g4 4 Gb Ram 1...</td>\n",
       "      <td>6.959 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>(6)</td>\n",
       "      <td>X515ja-ej3064w Fhd I3-1005g1 4g 256 Pcie Share...</td>\n",
       "      <td>7.024,90 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER</td>\n",
       "      <td>(6)</td>\n",
       "      <td>AspÄ±re 3 A315-510 Intel I3 8gb Ram 256ssd 15.6...</td>\n",
       "      <td>7.745 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACER</td>\n",
       "      <td>(3)</td>\n",
       "      <td>Nitro 5 An515-45-r423 Notebook (nh.qbaey.005)</td>\n",
       "      <td>17.499 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACER</td>\n",
       "      <td>(45)</td>\n",
       "      <td>Aspire3 A315-56-33zg Intel Core I3 1005g1 4gb ...</td>\n",
       "      <td>6.794 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>(1)</td>\n",
       "      <td>X515ea-bq868 I3-1115g4 8 Gb 256 Gb Ssd 15.6\" F...</td>\n",
       "      <td>8.499 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP</td>\n",
       "      <td>(46)</td>\n",
       "      <td>Pavilion 14-dv0012nt Core I5 1135g7 8gb 256gb ...</td>\n",
       "      <td>13.999 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LENOVO</td>\n",
       "      <td>(35)</td>\n",
       "      <td>IdeaPad Gaming3 Ryzen7 5800H 16GB 512GB SSD RT...</td>\n",
       "      <td>25.999 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>(41)</td>\n",
       "      <td>X515ea-bq868 I3-1115g4 8 Gb 512 Gb Ssd 15.6\" F...</td>\n",
       "      <td>8.799 TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>(16)</td>\n",
       "      <td>Matebook D15 I3 10110u 8gb 256gb Ssd W10 Home ...</td>\n",
       "      <td>12.685 TL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Rating_Count                                               Info  \\\n",
       "0    ASUS         (65)  X515ea-bq2293w Intel Core I3-1115g4 4 Gb Ram 1...   \n",
       "1    ASUS          (6)  X515ja-ej3064w Fhd I3-1005g1 4g 256 Pcie Share...   \n",
       "2    ACER          (6)  AspÄ±re 3 A315-510 Intel I3 8gb Ram 256ssd 15.6...   \n",
       "3    ACER          (3)      Nitro 5 An515-45-r423 Notebook (nh.qbaey.005)   \n",
       "4    ACER         (45)  Aspire3 A315-56-33zg Intel Core I3 1005g1 4gb ...   \n",
       "5    ASUS          (1)  X515ea-bq868 I3-1115g4 8 Gb 256 Gb Ssd 15.6\" F...   \n",
       "6      HP         (46)  Pavilion 14-dv0012nt Core I5 1135g7 8gb 256gb ...   \n",
       "7  LENOVO         (35)  IdeaPad Gaming3 Ryzen7 5800H 16GB 512GB SSD RT...   \n",
       "8    ASUS         (41)  X515ea-bq868 I3-1115g4 8 Gb 512 Gb Ssd 15.6\" F...   \n",
       "9  Huawei         (16)  Matebook D15 I3 10110u 8gb 256gb Ssd W10 Home ...   \n",
       "\n",
       "         Price  \n",
       "0     6.959 TL  \n",
       "1  7.024,90 TL  \n",
       "2     7.745 TL  \n",
       "3    17.499 TL  \n",
       "4     6.794 TL  \n",
       "5     8.499 TL  \n",
       "6    13.999 TL  \n",
       "7    25.999 TL  \n",
       "8     8.799 TL  \n",
       "9    12.685 TL  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=['Brand','Rating_Count', 'Info', 'Price'])\n",
    "df['Brand']=pd.DataFrame(brand)\n",
    "df['Rating_Count']=pd.DataFrame(ratingCount)\n",
    "df['Info']=pd.DataFrame(info)\n",
    "df['Price']=pd.DataFrame(price)\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33fb0ac0",
   "metadata": {},
   "source": [
    "Thank for reading ðŸ˜€\n",
    "\n",
    "Don't forget to follow us on [YouTube](http://youtube.com/@Be.Analyst) | [Medium](https://medium.com/@durgeshanalyst) | [Twitter](https://twitter.com/DurgeshBR?t=2LDCN4pHkZOYIo3rMXvKnw&s=09) | [GitHub](http://github.com/durgeshanalyst) | [Linkedin](https://www.linkedin.com/in/durgeshanalyst/) | [Kaggle](https://www.kaggle.com/durgeshanalyst) ðŸ˜Ž"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
